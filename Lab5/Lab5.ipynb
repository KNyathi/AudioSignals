{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6082e12b",
   "metadata": {},
   "source": [
    "### Вариант 17, mодель: Matcha TTS, язык: kyrgyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c8fb9",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d45c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchaudio in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: accelerate in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (0.48.2)\n",
      "Requirement already satisfied: transformers in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: soundfile in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: requests in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (4.14.2)\n",
      "Requirement already satisfied: filelock in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/nyathi/AudioSignals/venv/lib/python3.10/site-packages (from accelerate) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio accelerate bitsandbytes transformers soundfile numpy requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import time\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e52df",
   "metadata": {},
   "source": [
    "#### Text generation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d603ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_digits_or_abbreviations(text):\n",
    "    \"\"\"Check if text contains digits or multiple capital letters (abbreviations)\"\"\"\n",
    "    # Check for digits\n",
    "    if re.search(r'\\d', text):\n",
    "        return True\n",
    "    \n",
    "    # Count consecutive capital letters or multiple capital words\n",
    "    capital_words = re.findall(r'\\b[A-ZА-ЯӨҮӘ]{2,}\\b', text)\n",
    "    if capital_words:\n",
    "        return True\n",
    "    \n",
    "    # Check for single words with multiple consecutive capitals\n",
    "    if re.search(r'[A-ZА-ЯӨҮӘ]{3,}', text):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_kyrgyz_text(text):\n",
    "    \"\"\"Clean and format Kyrgyz text\"\"\"\n",
    "    # Remove extra spaces, newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove content in brackets and parentheses\n",
    "    text = re.sub(r'[\\[\\(][^\\]\\)]*[\\]\\)]', '', text)\n",
    "    \n",
    "    # Remove special characters but keep Kyrgyz letters and basic punctuation\n",
    "    text = re.sub(r'[^\\w\\sәөүҥңһіӊӨҮӘҢҺ.,!?;:—–-]', '', text)\n",
    "    \n",
    "    # Skip sentences with digits or abbreviations\n",
    "    if contains_digits_or_abbreviations(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Don't add period if sentence already ends with ; or other punctuation\n",
    "    if text and not text[0].isupper():\n",
    "        text = text[0].upper() + text[1:]\n",
    "    if text and not text.endswith(('.', '!', '?', ';', ':')):\n",
    "        text += '.'\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebe61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_kyrgyz_text(text):\n",
    "    \"\"\"Check if text contains Kyrgyz characters or keywords\"\"\"\n",
    "    kyrgyz_chars = set('әөүҥңһіӊӨҮӘҢҺ')\n",
    "    kyrgyz_keywords = [\n",
    "        'кыргыз', 'бишкек', 'ош', 'жалал', 'кыргызстан', 'бакай', \n",
    "        'талдык', 'нарын', 'иссык', 'чыгыш', 'батыш', 'түндүк',\n",
    "        'түштүк', 'жаштар', 'маданият', 'тарых', 'билим', 'дене',\n",
    "        'саламаттык', 'экономика', 'саясат', 'коом', 'спорт', 'бизнес',\n",
    "        'мамлекет', 'өкмөт', 'президент', 'министр', 'парламент',\n",
    "        'адам', 'жаран', 'кызмат', 'иш', 'соода', 'базар', 'бакча',\n",
    "        'мектеп', 'университет', 'оорукана', 'дарыгер', 'мугалим',\n",
    "        'китеп', 'окуу', 'жазуу', 'сүйлөө', 'угуу', 'көрүү', 'ичүү',\n",
    "        'жеңил', 'оор', 'жылуу', 'муздак', 'жаңы', 'эски', 'чоң', 'кичине',\n",
    "        'күн', 'ай', 'жыл', 'убакыт', 'жер', 'суу', 'аба', 'отун', 'тамак'\n",
    "    ]\n",
    "    \n",
    "    has_kyrgyz_chars = any(char in kyrgyz_chars for char in text.lower())\n",
    "    has_kyrgyz_words = any(keyword in text.lower() for keyword in kyrgyz_keywords)\n",
    "    \n",
    "    return has_kyrgyz_chars or has_kyrgyz_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_rich_wikipedia_pages():\n",
    "    \"\"\"Get only Wikipedia pages that are known to have extensive content\"\"\"\n",
    "    content_rich_pages = [\n",
    "        # MAJOR HISTORICAL EVENTS (very long articles)\n",
    "        \"https://ky.wikipedia.org/wiki/Биринчи_дүйнөлүк_согуш\",\n",
    "        \"https://ky.wikipedia.org/wiki/Экинчи_дүйнөлүк_согуш\", \n",
    "        \"https://ky.wikipedia.org/wiki/Улуу_Ата_Мекендик_согуш\",\n",
    "        \"https://ky.wikipedia.org/wiki/Чыңгыз_хан\",\n",
    "        \"https://ky.wikipedia.org/wiki/Осмон_империясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Рим_империясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Византия_империясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Моңгол_империясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Француз_революциясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Октябрь_революциясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Америка_революциясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кытай_революциясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Корея_согушу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Вьетнам_согушу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Афганстан_согушу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Байтак_согуштар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жылаңач_согуш\",\n",
    "        \n",
    "        # COMPREHENSIVE COUNTRIES (very long articles)\n",
    "        \"https://ky.wikipedia.org/wiki/Орусия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кытай\",\n",
    "        \"https://ky.wikipedia.org/wiki/Индия\", \n",
    "        \"https://ky.wikipedia.org/wiki/АКШ\",\n",
    "        \"https://ky.wikipedia.org/wiki/Германия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Франция\",\n",
    "        \"https://ky.wikipedia.org/wiki/Улуу_Британия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Япония\",\n",
    "        \"https://ky.wikipedia.org/wiki/Корея\",\n",
    "        \"https://ky.wikipedia.org/wiki/Түркия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Иран\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мысыр\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бразилия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Канада\",\n",
    "        \"https://ky.wikipedia.org/wiki/Австралия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мексика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Индонезия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Пакистан\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бангладеш\",\n",
    "        \"https://ky.wikipedia.org/wiki/Нигерия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эфиопия\",\n",
    "        \n",
    "        # MAJOR SCIENTIFIC TOPICS (very detailed)\n",
    "        \"https://ky.wikipedia.org/wiki/Күн_системасы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жер_планетасы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Ай\",\n",
    "        \"https://ky.wikipedia.org/wiki/Марс\",\n",
    "        \"https://ky.wikipedia.org/wiki/Юпитер\",\n",
    "        \"https://ky.wikipedia.org/wiki/Сатурн\",\n",
    "        \"https://ky.wikipedia.org/wiki/Галактика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жылдыздар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кара_тешиктер\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эволюция_теориясы\",\n",
    "        \"https://ky.wikipedia.org/wiki/ДНК\",\n",
    "        \"https://ky.wikipedia.org/wiki/Генетика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Клетка\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бактериялар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Вирустар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Иммунитет_системасы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Неврология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Психология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Психиатрия\",\n",
    "        \n",
    "        # TECHNOLOGY AND INNOVATION (long articles)\n",
    "        \"https://ky.wikipedia.org/wiki/Компьютер\",\n",
    "        \"https://ky.wikipedia.org/wiki/Интернет\",\n",
    "        \"https://ky.wikipedia.org/wiki/Искусственный_интеллект\",\n",
    "        \"https://ky.wikipedia.org/wiki/Робототехника\",\n",
    "        \"https://ky.wikipedia.org/wiki/Нанотехнология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Биотехнология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Космонавтика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Авиация\",\n",
    "        \"https://ky.wikipedia.org/wiki/Телевидение\",\n",
    "        \"https://ky.wikipedia.org/wiki/Радио\",\n",
    "        \"https://ky.wikipedia.org/wiki/Телефон\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мобилдик_телефон\",\n",
    "        \"https://ky.wikipedia.org/wiki/Социальдык_тармактар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Киберкоопсуздук\",\n",
    "        \"https://ky.wikipedia.org/wiki/Виртуалдык_реальность\",\n",
    "        \n",
    "        # MAJOR LITERARY WORKS AND AUTHORS\n",
    "        \"https://ky.wikipedia.org/wiki/Манас_эпосу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Чыңгыз_Айтматов\",\n",
    "        \"https://ky.wikipedia.org/wiki/Лев_Толстой\",\n",
    "        \"https://ky.wikipedia.org/wiki/Фёдор_Достоевский\",\n",
    "        \"https://ky.wikipedia.org/wiki/Антон_Чехов\",\n",
    "        \"https://ky.wikipedia.org/wiki/Александр_Пушкин\",\n",
    "        \"https://ky.wikipedia.org/wiki/Уильям_Шекспир\",\n",
    "        \"https://ky.wikipedia.org/wiki/Чарльз_Диккенс\",\n",
    "        \"https://ky.wikipedia.org/wiki/Марк_Твен\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эрнест_Хемингуэй\",\n",
    "        \"https://ky.wikipedia.org/wiki/Джордж_Оруэлл\",\n",
    "        \"https://ky.wikipedia.org/wiki/Джон_Толкин\",\n",
    "        \"https://ky.wikipedia.org/wiki/Джоан_Роулинг\",\n",
    "        \n",
    "        # WORLD RELIGIONS AND PHILOSOPHY\n",
    "        \"https://ky.wikipedia.org/wiki/Ислам\",\n",
    "        \"https://ky.wikipedia.org/wiki/Христианство\",\n",
    "        \"https://ky.wikipedia.org/wiki/Буддизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Иудаизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Индуизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Конфуций\",\n",
    "        \"https://ky.wikipedia.org/wiki/Даосизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Сикхизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Философия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Этика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Логика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Метафизика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эпистемология\",\n",
    "        \n",
    "        # MAJOR ECONOMIC SYSTEMS\n",
    "        \"https://ky.wikipedia.org/wiki/Экономика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Капитализм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Социализм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Коммунизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Глобализация\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эл_аралык_соода\",\n",
    "        \"https://ky.wikipedia.org/wiki/Банк_системасы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Валюта\",\n",
    "        \"https://ky.wikipedia.org/wiki/Биржа\",\n",
    "        \"https://ky.wikipedia.org/wiki/Инфляция\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эмгек_базары\",\n",
    "        \"https://ky.wikipedia.org/wiki/Каржы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Инвестиция\",\n",
    "        \n",
    "        # COMPREHENSIVE HEALTH AND MEDICINE\n",
    "        \"https://ky.wikipedia.org/wiki/Медицина\",\n",
    "        \"https://ky.wikipedia.org/wiki/Анатомия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Физиология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Фармакология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Хирургия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Педиатрия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кардиология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Неврология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Онкология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эпидемиология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Вирусология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бактериология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Генетикалык_инженерия\",\n",
    "        \n",
    "        # MAJOR ART FORMS AND MOVEMENTS\n",
    "        \"https://ky.wikipedia.org/wiki/Сүрөт_искусствосу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Музыка\",\n",
    "        \"https://ky.wikipedia.org/wiki/Театр\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кино\",\n",
    "        \"https://ky.wikipedia.org/wiki/Архитектура\",\n",
    "        \"https://ky.wikipedia.org/wiki/Адабият\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бий\",\n",
    "        \"https://ky.wikipedia.org/wiki/Опера\",\n",
    "        \"https://ky.wikipedia.org/wiki/Балет\",\n",
    "        \"https://ky.wikipedia.org/wiki/Фотография\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дизайн\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мода\",\n",
    "        \n",
    "        # COMPREHENSIVE SPORTS\n",
    "        \"https://ky.wikipedia.org/wiki/Олимпиада_оюндары\",\n",
    "        \"https://ky.wikipedia.org/wiki/Футбол\",\n",
    "        \"https://ky.wikipedia.org/wiki/Баскетбол\",\n",
    "        \"https://ky.wikipedia.org/wiki/Волейбол\",\n",
    "        \"https://ky.wikipedia.org/wiki/Теннис\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бейсбол\",\n",
    "        \"https://ky.wikipedia.org/wiki/Крикет\",\n",
    "        \"https://ky.wikipedia.org/wiki/Гольф\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бокс\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дзюдо\",\n",
    "        \"https://ky.wikipedia.org/wiki/Карате\",\n",
    "        \"https://ky.wikipedia.org/wiki/Таэквондо\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жеңил_атлетика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Суу_спорту\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кышкы_спорттор\",\n",
    "        \n",
    "        # MAJOR ENVIRONMENTAL TOPICS\n",
    "        \"https://ky.wikipedia.org/wiki/Климат_өзгөрүүсү\",\n",
    "        \"https://ky.wikipedia.org/wiki/Глобалдык_жылынуу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Экология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Биоар түрдүүлүк\",\n",
    "        \"https://ky.wikipedia.org/wiki/Токойлор\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дарыялар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Океандар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Атмосфера\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жер_кыртышы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Табигый_байлыктар\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кайра_иштетүү\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эко_система\",\n",
    "        \n",
    "        # MAJOR POLITICAL SYSTEMS\n",
    "        \"https://ky.wikipedia.org/wiki/Демократия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Монархия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Республика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Диктатура\",\n",
    "        \"https://ky.wikipedia.org/wiki/Фашизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Нацизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Анархизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Либерализм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Консерватизм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Национализм\",\n",
    "        \"https://ky.wikipedia.org/wiki/Интернационализм\",\n",
    "        \n",
    "        # COMPREHENSIVE EDUCATION\n",
    "        \"https://ky.wikipedia.org/wiki/Билим_берүү\",\n",
    "        \"https://ky.wikipedia.org/wiki/Педагогика\",\n",
    "        \"https://ky.wikipedia.org/wiki/Психология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Социология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Университет\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мектеп\",\n",
    "        \"https://ky.wikipedia.org/wiki/Колледж\",\n",
    "        \"https://ky.wikipedia.org/wiki/Академия\",\n",
    "        \"https://ky.wikipedia.org/wiki/Илим\",\n",
    "        \"https://ky.wikipedia.org/wiki/Технология\",\n",
    "        \"https://ky.wikipedia.org/wiki/Инженердик\",\n",
    "        \"https://ky.wikipedia.org/wiki/Медициналык_билим\",\n",
    "        \n",
    "        # WORLD CULTURES AND CIVILIZATIONS\n",
    "        \"https://ky.wikipedia.org/wiki/Кыргыз_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Орус_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кытай_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Индия_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Япония_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Корея_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Араб_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Европа_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Африка_маданияты\",\n",
    "        \"https://ky.wikipedia.org/wiki/Латын_Америкасынын_маданияты\",\n",
    "        \n",
    "        # MAJOR LANGUAGES AND LINGUISTICS\n",
    "        \"https://ky.wikipedia.org/wiki/Кыргыз_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Орус_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Англис_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кытай_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Араб_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Испан_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Француз_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Немис_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Япон_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Корей_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Түрк_тили\",\n",
    "        \"https://ky.wikipedia.org/wiki/Фарсы_тили\",\n",
    "        \n",
    "        # MAJOR INVENTIONS AND DISCOVERIES\n",
    "        \"https://ky.wikipedia.org/wiki/Телеграф\",\n",
    "        \"https://ky.wikipedia.org/wiki/Телефон\",\n",
    "        \"https://ky.wikipedia.org/wiki/Радио\",\n",
    "        \"https://ky.wikipedia.org/wiki/Телевидение\",\n",
    "        \"https://ky.wikipedia.org/wiki/Компьютер\",\n",
    "        \"https://ky.wikipedia.org/wiki/Интернет\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мобилдик_телефон\",\n",
    "        \"https://ky.wikipedia.org/wiki/Пенициллин\",\n",
    "        \"https://ky.wikipedia.org/wiki/Вакцина\",\n",
    "        \"https://ky.wikipedia.org/wiki/Рентген\",\n",
    "        \"https://ky.wikipedia.org/wiki/Микроскоп\",\n",
    "        \"https://ky.wikipedia.org/wiki/Телескоп\",\n",
    "        \"https://ky.wikipedia.org/wiki/Пар_машинасы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Ички_күйүү_кыймылдаткычы\",\n",
    "        \n",
    "        # WORLD ORGANIZATIONS\n",
    "        \"https://ky.wikipedia.org/wiki/БУУ\",\n",
    "        \"https://ky.wikipedia.org/wiki/НАТО\",\n",
    "        \"https://ky.wikipedia.org/wiki/Евросоюз\",\n",
    "        \"https://ky.wikipedia.org/wiki/Азия_өнүктүрүү_банкы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дүйнөлүк_банк\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эл_аралык_валютa_фонду\",\n",
    "        \"https://ky.wikipedia.org/wiki/ЮНЕСКО\",\n",
    "        \"https://ky.wikipedia.org/wiki/БУУнун_Балдар_фонду\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дүйнөлүк_соода_уюму\",\n",
    "        \n",
    "        # MAJOR CITIES OF THE WORLD\n",
    "        \"https://ky.wikipedia.org/wiki/Москва\",\n",
    "        \"https://ky.wikipedia.org/wiki/Пекин\",\n",
    "        \"https://ky.wikipedia.org/wiki/Токио\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дели\",\n",
    "        \"https://ky.wikipedia.org/wiki/Нью-Йорк\",\n",
    "        \"https://ky.wikipedia.org/wiki/Лондон\",\n",
    "        \"https://ky.wikipedia.org/wiki/Париж\",\n",
    "        \"https://ky.wikipedia.org/wiki/Берлин\",\n",
    "        \"https://ky.wikipedia.org/wiki/Рим\",\n",
    "        \"https://ky.wikipedia.org/wiki/Мадрид\",\n",
    "        \"https://ky.wikipedia.org/wiki/Стамбул\",\n",
    "        \"https://ky.wikipedia.org/wiki/Каир\",\n",
    "        \"https://ky.wikipedia.org/wiki/Сиэтл\",\n",
    "        \"https://ky.wikipedia.org/wiki/Сидней\",\n",
    "        \"https://ky.wikipedia.org/wiki/Рио-де-Жанейро\",\n",
    "        \n",
    "        # MAJOR RIVERS AND MOUNTAINS\n",
    "        \"https://ky.wikipedia.org/wiki/Амазонка\",\n",
    "        \"https://ky.wikipedia.org/wiki/Нил\",\n",
    "        \"https://ky.wikipedia.org/wiki/Янцзы\",\n",
    "        \"https://ky.wikipedia.org/wiki/Миссисипи\",\n",
    "        \"https://ky.wikipedia.org/wiki/Волга\",\n",
    "        \"https://ky.wikipedia.org/wiki/Дунай\",\n",
    "        \"https://ky.wikipedia.org/wiki/Ганг\",\n",
    "        \"https://ky.wikipedia.org/wiki/Эверест\",\n",
    "        \"https://ky.wikipedia.org/wiki/Альп тоолору\",\n",
    "        \"https://ky.wikipedia.org/wiki/Анды\",\n",
    "        \"https://ky.wikipedia.org/wiki/Рокки тоолору\",\n",
    "        \"https://ky.wikipedia.org/wiki/Урал тоолору\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кавказ тоолору\",\n",
    "        \n",
    "        # MAJOR OCEANS AND SEAS\n",
    "        \"https://ky.wikipedia.org/wiki/Тынч_океан\",\n",
    "        \"https://ky.wikipedia.org/wiki/Атлантика_океаны\",\n",
    "        \"https://ky.wikipedia.org/wiki/Инди_океаны\",\n",
    "        \"https://ky.wikipedia.org/wiki/Түндүк_Муз_океаны\",\n",
    "        \"https://ky.wikipedia.org/wiki/Түштүк_океан\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кариб_деңизи\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жер_орта_деңизи\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кызыл_деңиз\",\n",
    "        \"https://ky.wikipedia.org/wiki/Каспий_деңизи\",\n",
    "        \"https://ky.wikipedia.org/wiki/Балтика_деңизи\",\n",
    "        \n",
    "        # MAJOR ANIMALS AND PLANTS\n",
    "        \"https://ky.wikipedia.org/wiki/Аюу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бөрү\",\n",
    "        \"https://ky.wikipedia.org/wiki/Түлкү\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жолборс\",\n",
    "        \"https://ky.wikipedia.org/wiki/Арстан\",\n",
    "        \"https://ky.wikipedia.org/wiki/Пил\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жираф\",\n",
    "        \"https://ky.wikipedia.org/wiki/Зебра\",\n",
    "        \"https://ky.wikipedia.org/wiki/Крокодил\",\n",
    "        \"https://ky.wikipedia.org/wiki/Ак_сарык\",\n",
    "        \"https://ky.wikipedia.org/wiki/Бугу\",\n",
    "        \"https://ky.wikipedia.org/wiki/Кой\",\n",
    "        \"https://ky.wikipedia.org/wiki/Жылкы\",\n",
    "    ]\n",
    "    \n",
    "    return content_rich_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_content_rich_page(url, headers, min_sentences=5):\n",
    "    \"\"\"Scrape pages that are known to have extensive content\"\"\"\n",
    "    sentences = []\n",
    "    \n",
    "    try:\n",
    "        print(f\"Scraping content-rich page: {url}\")\n",
    "        response = requests.get(url, timeout=30, headers=headers)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the main content area\n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        if not content_div:\n",
    "            return sentences\n",
    "        \n",
    "        # Extract ALL text elements including lists\n",
    "        elements = content_div.find_all(['p', 'li', 'div'])\n",
    "        \n",
    "        for elem in elements:\n",
    "            text = elem.get_text().strip()\n",
    "            if len(text) > 20:  # Only substantial content\n",
    "                # Split into sentences\n",
    "                raw_sentences = re.split(r'[.!?]', text)\n",
    "                \n",
    "                for sentence in raw_sentences:\n",
    "                    sentence = sentence.strip()\n",
    "                    if len(sentence) > 15:\n",
    "                        cleaned = clean_kyrgyz_text(sentence)\n",
    "                        if cleaned and is_kyrgyz_text(cleaned):\n",
    "                            words = cleaned.split()\n",
    "                            if 7 <= len(words) <= 70:  # Wider range for content-rich pages\n",
    "                                if cleaned not in sentences:\n",
    "                                    sentences.append(cleaned)\n",
    "        \n",
    "        print(f\"  Extracted {len(sentences)} sentences from this page\")\n",
    "        \n",
    "        # If this page has good content, explore its main links\n",
    "        if len(sentences) >= min_sentences:\n",
    "            print(f\"  Page has good content, exploring related pages...\")\n",
    "            related_sentences = explore_related_pages(url, headers, sentences)\n",
    "            sentences.extend(related_sentences)\n",
    "        \n",
    "        return sentences\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error scraping {url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baed656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_related_pages(main_url, headers, existing_sentences, max_related=10):\n",
    "    \"\"\"Explore related pages from a content-rich page\"\"\"\n",
    "    related_sentences = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(main_url, timeout=20, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        if not content_div:\n",
    "            return related_sentences\n",
    "        \n",
    "        # Find main section links (usually in the first part of the article)\n",
    "        links = content_div.find_all('a', href=True)\n",
    "        related_urls = []\n",
    "        \n",
    "        for link in links[:100]:  # Check first 100 links\n",
    "            href = link['href']\n",
    "            if (href.startswith('/wiki/') and \n",
    "                ':' not in href and\n",
    "                len(related_urls) < max_related):\n",
    "                \n",
    "                full_url = \"https://ky.wikipedia.org\" + href\n",
    "                if full_url not in related_urls:\n",
    "                    related_urls.append(full_url)\n",
    "        \n",
    "        # Scrape the related pages\n",
    "        for related_url in related_urls:\n",
    "            try:\n",
    "                response = requests.get(related_url, timeout=20, headers=headers)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                \n",
    "                content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "                if content_div:\n",
    "                    elements = content_div.find_all(['p', 'li'])\n",
    "                    \n",
    "                    for elem in elements:\n",
    "                        text = elem.get_text().strip()\n",
    "                        if len(text) > 20:\n",
    "                            raw_sentences = re.split(r'[.!?]', text)\n",
    "                            \n",
    "                            for sentence in raw_sentences:\n",
    "                                sentence = sentence.strip()\n",
    "                                if len(sentence) > 15:\n",
    "                                    cleaned = clean_kyrgyz_text(sentence)\n",
    "                                    if cleaned and is_kyrgyz_text(cleaned):\n",
    "                                        words = cleaned.split()\n",
    "                                        if 4 <= len(words) <= 60:\n",
    "                                            if cleaned not in existing_sentences and cleaned not in related_sentences:\n",
    "                                                related_sentences.append(cleaned)\n",
    "                    \n",
    "                    print(f\"    Added {len(related_sentences)} sentences from related page\")\n",
    "                    time.sleep(1)  # Brief pause between related pages\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    Error with related page {related_url}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error exploring related pages: {e}\")\n",
    "    \n",
    "    return related_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_content_rich_wikipedia(target_count=9000):\n",
    "    \"\"\"Scrape only content-rich Wikipedia pages\"\"\"\n",
    "    print(f\"Scraping content-rich Kyrgyz Wikipedia pages for {target_count} sentences...\")\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    all_sentences = []\n",
    "    content_rich_pages = get_content_rich_wikipedia_pages()\n",
    "    \n",
    "    print(f\"Targeting {len(content_rich_pages)} content-rich pages\")\n",
    "    \n",
    "    for page_url in content_rich_pages:\n",
    "        if len(all_sentences) >= target_count:\n",
    "            break\n",
    "            \n",
    "        sentences = scrape_content_rich_page(page_url, headers, min_sentences=30)\n",
    "        all_sentences.extend(sentences)\n",
    "        \n",
    "        print(f\"Total so far: {len(all_sentences)} sentences\")\n",
    "        \n",
    "        # Respectful delay\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    # Remove duplicates\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    for sentence in all_sentences:\n",
    "        if sentence not in seen:\n",
    "            seen.add(sentence)\n",
    "            unique_sentences.append(sentence)\n",
    "    \n",
    "    print(f\"\\nFinal unique sentences from content-rich pages: {len(unique_sentences)}\")\n",
    "    return unique_sentences[:target_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef028cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_file(sentences, filename=\"texts.txt\"):\n",
    "    \"\"\"Create the final text file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for sentence in sentences:\n",
    "            f.write(sentence + '\\n')\n",
    "    \n",
    "    print(f\"Created {filename} with {len(sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fff4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Content-Rich Kyrgyz Wikipedia Corpus Creation...\n",
      "This targets only pages with extensive content like World War I\n",
      "Scraping content-rich Kyrgyz Wikipedia pages for 9000 sentences...\n",
      "Targeting 238 content-rich pages\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстан\n",
      "  Extracted 220 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 220 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Бишкек\n",
      "  Extracted 140 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 360 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ош\n",
      "  Extracted 27 sentences from this page\n",
      "Total so far: 387 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жалал-Абад\n",
      "  Extracted 71 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 458 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Каракол\n",
      "  Extracted 33 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 491 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Токмок\n",
      "  Extracted 9 sentences from this page\n",
      "Total so far: 500 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ысык-Көл\n",
      "  Extracted 43 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 543 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ала-Тоо\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 546 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Тянь-Шань\n",
      "  Extracted 7 sentences from this page\n",
      "Total so far: 553 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Памир\n",
      "  Extracted 39 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 592 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Нарын\n",
      "  Extracted 19 sentences from this page\n",
      "Total so far: 611 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Баткен\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 614 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Талас\n",
      "  Extracted 16 sentences from this page\n",
      "Total so far: 630 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кочкор\n",
      "  Extracted 7 sentences from this page\n",
      "Total so far: 637 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Балыкчы\n",
      "  Extracted 8 sentences from this page\n",
      "Total so far: 645 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кара-Балта\n",
      "  Extracted 2 sentences from this page\n",
      "Total so far: 647 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Майлуу-Суу\n",
      "  Extracted 12 sentences from this page\n",
      "Total so far: 659 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кызыл-Кыя\n",
      "  Extracted 5 sentences from this page\n",
      "Total so far: 664 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сулюкта\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 665 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Исфана\n",
      "  Extracted 51 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 716 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чүй_облусу\n",
      "  Extracted 33 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 749 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ысык-Көл_облусу\n",
      "  Extracted 95 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 844 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Нарын_облусу\n",
      "  Extracted 112 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 956 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Баткен_облусу\n",
      "  Extracted 107 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1063 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жалал-Абад_облусу\n",
      "  Extracted 110 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1173 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ош_облусу\n",
      "  Extracted 55 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1228 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Талас_облусу\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 1231 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Алай_району\n",
      "  Extracted 32 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1263 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ак-Суу_району\n",
      "  Extracted 36 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1299 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Бакай-Ата_району\n",
      "  Extracted 13 sentences from this page\n",
      "Total so far: 1312 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жумгал_району\n",
      "  Extracted 28 sentences from this page\n",
      "Total so far: 1340 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кара-Кулжа_району\n",
      "  Extracted 21 sentences from this page\n",
      "Total so far: 1361 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ноокат_району\n",
      "  Extracted 31 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1392 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сузак_району\n",
      "  Extracted 18 sentences from this page\n",
      "Total so far: 1410 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Тоң_району\n",
      "  Extracted 22 sentences from this page\n",
      "Total so far: 1432 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Түп_району\n",
      "  Extracted 27 sentences from this page\n",
      "Total so far: 1459 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чаткал_району\n",
      "  Extracted 13 sentences from this page\n",
      "Total so far: 1472 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_тили\n",
      "  Extracted 55 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1527 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Манас\n",
      "  Extracted 168 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1695 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Семетей\n",
      "  Extracted 84 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1779 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сейтек\n",
      "  Extracted 47 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1826 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_эли\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 1827 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_маданияты\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 1828 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_адабияты\n",
      "  Extracted 83 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1911 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_музыкасы\n",
      "  Extracted 66 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 1977 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_кийимдери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 1978 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_тамактары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 1979 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_улуттук_оюндары\n",
      "  Extracted 30 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2009 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_фольклору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2010 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_мифологиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2011 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_салттары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2012 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_ырлары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2013 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_бийлери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2014 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Биринчи_дүйнөлүк_согуш\n",
      "  Extracted 12 sentences from this page\n",
      "Total so far: 2026 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Экинчи_дүйнөлүк_согуш\n",
      "  Extracted 34 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2060 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Улуу_Ата_Мекендик_согуш\n",
      "  Extracted 4 sentences from this page\n",
      "Total so far: 2064 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/СССРдин_тарыхы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2065 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Осмон_империясы\n",
      "  Extracted 41 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2106 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чыңгыз_хан\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 2109 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Бабур\n",
      "  Extracted 22 sentences from this page\n",
      "Total so far: 2131 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Тимур\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 2141 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Азия\n",
      "  Extracted 153 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2294 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Европа\n",
      "  Extracted 192 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2486 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Африка\n",
      "  Extracted 73 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2559 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Түндүк_Америка\n",
      "  Extracted 46 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2605 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Түштүк_Америка\n",
      "  Extracted 49 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2654 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Австралия\n",
      "  Extracted 196 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2850 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Антарктида\n",
      "  Extracted 6 sentences from this page\n",
      "Total so far: 2856 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чоң_океан\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 2857 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Атлантика_океаны\n",
      "  Extracted 36 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2893 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Инди_океаны\n",
      "  Extracted 44 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 2937 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Астрономия\n",
      "  Extracted 16 sentences from this page\n",
      "Total so far: 2953 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Физика\n",
      "  Extracted 14 sentences from this page\n",
      "Total so far: 2967 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Химия\n",
      "  Extracted 18 sentences from this page\n",
      "Total so far: 2985 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Биология\n",
      "  Extracted 14 sentences from this page\n",
      "Total so far: 2999 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Геология\n",
      "  Extracted 24 sentences from this page\n",
      "Total so far: 3023 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Метеорология\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 3033 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Экология\n",
      "  Extracted 30 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3063 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Генетика\n",
      "  Extracted 35 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3098 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Эволюция\n",
      "  Extracted 192 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3290 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Компьютер\n",
      "  Extracted 14 sentences from this page\n",
      "Total so far: 3304 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Интернет\n",
      "  Extracted 45 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3349 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Искусственный_интеллект\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3350 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Робототехника\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3351 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Космонавтика\n",
      "  Extracted 5 sentences from this page\n",
      "Total so far: 3356 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Нанотехнология\n",
      "  Extracted 2 sentences from this page\n",
      "Total so far: 3358 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Биотехнология\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 3368 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Манас_эпосу\n",
      "  Extracted 148 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3516 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_эл_жазуусу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3517 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_этнографиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3518 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_фольклору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3519 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_мифологиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3520 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_эпикалык_мурасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3521 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чыңгыз_Айтматов\n",
      "  Extracted 45 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3566 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Токтогул_Сатылганов\n",
      "  Extracted 41 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3607 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Алыкул_Осмонов\n",
      "  Extracted 61 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3668 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Касымалы_Жантөшев\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 3678 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Демократия\n",
      "  Extracted 15 sentences from this page\n",
      "Total so far: 3693 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Социализм\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 3696 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Капитализм\n",
      "  Extracted 14 sentences from this page\n",
      "Total so far: 3710 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Коммунизм\n",
      "  Extracted 19 sentences from this page\n",
      "Total so far: 3729 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Фашизм\n",
      "  Extracted 6 sentences from this page\n",
      "Total so far: 3735 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Экономика\n",
      "  Extracted 30 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3765 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Макроэкономика\n",
      "  Extracted 5 sentences from this page\n",
      "Total so far: 3770 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Микроэкономика\n",
      "  Extracted 4 sentences from this page\n",
      "Total so far: 3774 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Эл_аралык_экономика\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3775 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Медицина\n",
      "  Extracted 9 sentences from this page\n",
      "Total so far: 3784 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Анатомия\n",
      "  Extracted 11 sentences from this page\n",
      "Total so far: 3795 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Физиология\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 3805 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Фармакология\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 3815 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Эпидемиология\n",
      "  Extracted 33 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3848 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Билим_берүү\n",
      "  Extracted 8 sentences from this page\n",
      "Total so far: 3856 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Педагогика\n",
      "  Extracted 30 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 3886 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Психология\n",
      "  Extracted 15 sentences from this page\n",
      "Total so far: 3901 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Социология\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3902 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кино\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 3905 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Театр\n",
      "  Extracted 28 sentences from this page\n",
      "Total so far: 3933 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Музыка\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3934 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сүрөт_искусствосу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 3935 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Архитектура\n",
      "  Extracted 174 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4109 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Адабият\n",
      "  Extracted 18 sentences from this page\n",
      "Total so far: 4127 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Олимпиада_оюндары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4128 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Футбол\n",
      "  Extracted 15 sentences from this page\n",
      "Total so far: 4143 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Баскетбол\n",
      "  Extracted 18 sentences from this page\n",
      "Total so far: 4161 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Волейбол\n",
      "  Extracted 11 sentences from this page\n",
      "Total so far: 4172 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Легкая_атлетика\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4173 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Философия\n",
      "  Extracted 42 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4215 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ислам\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4216 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Христианство\n",
      "  Extracted 19 sentences from this page\n",
      "Total so far: 4235 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Буддизм\n",
      "  Extracted 64 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4299 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Иудаизм\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4300 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Климат_өзгөрүүсү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4301 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Экологиялык_проблемалар\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4302 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жаныбарлар_дүйнөсү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4303 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Өсүмдүктөр_дүйнөсү\n",
      "  Extracted 3 sentences from this page\n",
      "Total so far: 4306 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_тарыхы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4307 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_хандыгы\n",
      "  Extracted 66 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4373 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыздардын_орто_кылымдардагы_тарыхы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4374 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_ССРи\n",
      "  Extracted 0 sentences from this page\n",
      "Total so far: 4374 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_кеңеш_мезгилиндеги_тарыхы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4375 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_эркиндик_мезгилиндеги_тарыхы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4376 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_революциялары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4377 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_президенттери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4378 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чыңгыз_Айтматов\n",
      "  Extracted 45 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4423 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Токтогул_Сатылганов\n",
      "  Extracted 41 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4464 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Алыкул_Осмонов\n",
      "  Extracted 61 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4525 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Касымалы_Жантөшев\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 4535 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Суйунбай_Эралиев\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4536 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жоомарт_Бөкөнбаев\n",
      "  Extracted 15 sentences from this page\n",
      "Total so far: 4551 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кубанычбек_Маликов\n",
      "  Extracted 13 sentences from this page\n",
      "Total so far: 4564 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сооронбай_Жусуев\n",
      "  Extracted 19 sentences from this page\n",
      "Total so far: 4583 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Туголбай_Сыдыкбеков\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4584 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Мукай_Элебаев\n",
      "  Extracted 7 sentences from this page\n",
      "Total so far: 4591 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Абдылас_Малдыбаев\n",
      "  Extracted 11 sentences from this page\n",
      "Total so far: 4602 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Алыбай_Үсөнов\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4603 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Аскар_Акаев\n",
      "  Extracted 12 sentences from this page\n",
      "Total so far: 4615 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Курманбек_Бакиев\n",
      "  Extracted 13 sentences from this page\n",
      "Total so far: 4628 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Роза_Отунбаева\n",
      "  Extracted 23 sentences from this page\n",
      "Total so far: 4651 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сооронбай_Жээнбеков\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 4661 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Садыр_Жапаров\n",
      "  Extracted 14 sentences from this page\n",
      "Total so far: 4675 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Тянь-Шань\n",
      "  Extracted 7 sentences from this page\n",
      "Total so far: 4682 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Памир-Алай\n",
      "  Extracted 2 sentences from this page\n",
      "Total so far: 4684 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_флорасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4685 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_фаунасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4686 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_коруктары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4687 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_дарыялары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4688 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_көлдөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4689 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_тоолору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4690 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ала-Арча\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4691 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Арстанбап\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 4701 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Беш-Таш\n",
      "  Extracted 4 sentences from this page\n",
      "Total so far: 4705 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кара-Шоро\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4706 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Сары-Челек\n",
      "  Extracted 10 sentences from this page\n",
      "Total so far: 4716 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Чон-Кемин\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4717 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Каньон_Сказка\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4718 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Жети-Огуз\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4719 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Ала-Көл\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4720 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кель-Суу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4721 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_экономикасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4722 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_айыл_чарбасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4723 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_промышленностьы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4724 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_туризми\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4725 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_билим_берүү_системасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4726 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_медицинасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4727 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илими\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4728 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_технологиялары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4729 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_транспорту\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4730 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_байланышы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4731 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_энергетикасы\n",
      "  Extracted 4 sentences from this page\n",
      "Total so far: 4735 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_президенттери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4736 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_өкмөтү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4737 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_парламенти\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4738 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_конституциясы\n",
      "  Extracted 7 sentences from this page\n",
      "Total so far: 4745 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_системасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4746 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_саясий_партиялары\n",
      "  Extracted 0 sentences from this page\n",
      "Total so far: 4746 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_дипломатиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4747 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_аскер_күчтөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4748 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/731_%D0%BE%D1%82%D1%80%D1%8F%D0%B4%D1%8B\n",
      "  Extracted 19 sentences from this page\n",
      "Total so far: 4767 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_киносу\n",
      "  Extracted 30 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4797 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_театры\n",
      "  Extracted 105 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4902 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_балери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4903 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_сүрөтчүлөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4904 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_композиторлору\n",
      "  Extracted 31 sentences from this page\n",
      "  Page has good content, exploring related pages...\n",
      "Total so far: 4935 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_жазуучулары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4936 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_акындары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4937 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_фольклору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4938 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_китепканалары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4939 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_музейлери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4940 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_архитектурасы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4941 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_кол_өнөрчүлүгү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4942 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илимдер_академиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4943 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргыз_университеттери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4944 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илимий_изилдөөлөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4945 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илим_ишмерлери\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4946 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илим_борборлору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4947 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_илимий_журналдары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4948 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_спорту\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4949 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_футболу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4950 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_күрөшү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4951 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_олимпиада_оюндары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4952 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_спортчулары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4953 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_боксу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4954 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_джиу-джитсу\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4955 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_альпинизми\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4956 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_шахматы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4957 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_жайыттары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4958 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_өсүмдүктөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4959 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_жайлоолору\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4960 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_токойлору\n",
      "  Extracted 9 sentences from this page\n",
      "Total so far: 4969 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_жапайы_жаныбарлары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4970 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_куштары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4971 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_балыктары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4972 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_этнографиясы\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4973 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_устаттары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4974 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_кол_өнөрчүлөрү\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4975 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_улуттук_салттары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4976 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_ырчылары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4977 sentences\n",
      "Scraping content-rich page: https://ky.wikipedia.org/wiki/Кыргызстандын_комузчулары\n",
      "  Extracted 1 sentences from this page\n",
      "Total so far: 4978 sentences\n",
      "\n",
      "Final unique sentences from content-rich pages: 4602\n",
      "Created texts.txt with 4602 sentences\n",
      "\n",
      "=== CONTENT-RICH CORPUS CREATION COMPLETE ===\n",
      "Total sentences: 4602\n",
      "Note: Collected 4602 sentences (target was 9000)\n",
      "The synthesis will use whatever we collected\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Content-Rich Kyrgyz Wikipedia Corpus Creation...\")\n",
    "    print(\"This targets only pages with extensive content like World War I\")\n",
    "    \n",
    "    sentences = scrape_content_rich_wikipedia(9000)\n",
    "    \n",
    "    create_text_file(sentences, \"texts.txt\")\n",
    "    \n",
    "    print(f\"\\n=== CONTENT-RICH CORPUS CREATION COMPLETE ===\")\n",
    "    print(f\"Total sentences: {len(sentences)}\")\n",
    "    \n",
    "    if len(sentences) < 9000:\n",
    "        print(f\"Note: Collected {len(sentences)} sentences (target was 9000)\")\n",
    "        print(\"The synthesis will use whatever we collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_with_ollama(prompt, model=\"deepseek-coder-v2:latest\"):\\n    \"\"\"Generate natural Kyrgyz sentences about coding topics\"\"\"\\n    url = \"http://localhost:11434/api/generate\" #ollama hosted locally\\n    \\n    # More natural prompt without definition structure\\n    enhanced_prompt = f\"\"\"\\nСиз программалоо жана технология темасында табигый кыргыз тилинде сүйлөмдөр жаратуучу AI болосуз.\\n\\nТема: {prompt}\\n\\nЖарыялоо: Бул тема боюнча 7-15 сөздөн турган табигый, толук сүйлөм жаратыңыз.\\n- Сүйлөм табигый кыргыз тилинде болсун\\n- Англис сөздөрүн колдонбоңуз\\n- Аныктама бербеңиз\\n- Сүйлөм баш тамга менен башталып, чекит менен бүтсүн\\n- Сүйлөм табигый жана коомдо колдонулган сыяктуу болсун\\n\\nСүйлөм:\"\"\"\\n    \\n    payload = {\\n        \"model\": model,\\n        \"prompt\": enhanced_prompt,\\n        \"stream\": False,\\n        \"options\": {\\n            \"temperature\": 0.9,  # Increased for more creativity\\n            \"num_predict\": 100,\\n            \"top_p\": 0.95,\\n            \"repeat_penalty\": 1.3\\n        }\\n    }\\n    \\n    try:\\n        response = requests.post(url, json=payload, timeout=120)\\n        if response.status_code == 200:\\n            result = response.json()\\n            return result[\"response\"].strip()\\n        else:\\n            print(f\"API error {response.status_code}: {response.text}\")\\n            return None\\n    except Exception as e:\\n        print(f\"Request failed: {e}\")\\n        return None\\n\\ndef generate_coding_sentences_ollama(num_sentences=9000):\\n    \"\"\"Generate natural coding/programming sentences in Kyrgyz\"\"\"\\n    \\n    # More conversational topics that encourage natural sentences\\n    coding_topics = [\\n        # Programming experiences\\n        \"Python менен программа жазуунун жакшы тараптары\",\\n        \"Java колдонуп жаңы проект түзүү\",\\n        \"JavaScript жардамында динамикалык веб-беттер\",\\n        \"C++ менен ыңгайлуу колдонмолор иштеп чыгуу\",\\n        \"PHP аркылуу сервердик скриптер жазуу\",\\n        \"Ruby программалоо тилин үйрөнүү тажрыйбасы\",\\n        \\n        # Daily programming activities\\n        \"Код жазууда колдонулуучу негизги каражаттар\",\\n        \"Программа иштебей калганда кылган аракеттер\",\\n        \"Жаңы функция кошуудан мурун кандай даярдык кылуу\",\\n        \"Башка программачылар менен бирге иштөө\",\\n        \"Колдонмонун ырачатын жакшыртуу үчүн аракеттер\",\\n        \"Кодду текшерүү жана оңдоо процесси\",\\n        \\n        # Learning and development\\n        \"Программалоо тилин үйрөнүүдөгү кыйынчылыктар\",\\n        \"Алгачкы программаңызды иштеткендеги сезимдер\",\\n        \"Технологиялык жаңылыктарды күндөлүк көзөмөлдөө\",\\n        \"Программалоо боюнча коомдук иш-чараларга катышуу\",\\n        \"Жаңы технологияларды долбоордо колдонуу\",\\n        \"Код жазуунун жакшы ыкмаларын үйрөнүү\",\\n        \\n        # Project scenarios\\n        \"Ири проектти аяктоодон кийинки баалоо\",\\n        \"Топ менен иштөөдө коммуникациянын маанилүүлүгү\",\\n        \"Колдонмонун иштешине мониторинг жүргүзүү\",\\n        \"Жаңы версия чыгарганда эске алынуучу жабдуулар\",\\n        \"Колдонуучулардын пикири боюнча өзгөртүүлөр киргизүү\",\\n        \"Программанын коопсуздугун камсыз кылуу чаралары\",\\n        \\n        # Problem solving\\n        \"Программа иштебей калганда издөө ыкмалары\",\\n        \"Кыйын маселе чечүү үчүн колдонулган стратегиялар\",\\n        \"Кодду оңдоодо кезиккен кызыктуу учурлар\",\\n        \"Башка адамдын кодун түшүнүүгө болгон машыгуу\",\\n        \"Программанын ырачатын жогорулатуу жолдору\",\\n        \"Техникалык көйгөй чечүүдөгү тажрыйбалар\"\\n    ]\\n    \\n    sentences = []\\n    attempts = 0\\n    max_attempts = num_sentences * 2\\n    \\n    print(f\"Starting generation of {num_sentences} natural coding sentences...\")\\n    \\n    while len(sentences) < num_sentences and attempts < max_attempts:\\n        topic = random.choice(coding_topics)\\n        \\n        generated_text = generate_with_ollama(topic)\\n        attempts += 1\\n        \\n        if generated_text:\\n            # Extract just the sentence part\\n            sentence = extract_sentence(generated_text)\\n            sentence = clean_sentence(sentence)\\n            \\n            if is_valid_natural_sentence(sentence):\\n                sentences.append(sentence)\\n                print(f\"[{len(sentences)}/{num_sentences}] {sentence}\")\\n                \\n                # Save progress regularly\\n                if len(sentences) % 100 == 0:\\n                    save_progress(sentences, f\"progress_{len(sentences)}.txt\")\\n                    print(f\"Progress saved: {len(sentences)} sentences\")\\n            else:\\n                if attempts % 10 == 0:\\n                    print(f\"Attempt {attempts}: Retrying... Last output: {sentence[:60]}...\")\\n        else:\\n            print(f\"Generation failed on attempt {attempts}\")\\n        \\n        # Rate limiting\\n        time.sleep(1.5)  # Slightly longer delay for better quality\\n    \\n    return sentences\\n\\ndef extract_sentence(text):\\n    \"\"\"Extract the actual sentence from generated text\"\"\"\\n    # Remove any prompt remnants\\n    if \"Сүйлөм:\" in text:\\n        text = text.split(\"Сүйлөм:\")[-1].strip()\\n    \\n    # Split into sentences and take the first complete one\\n    sentences = re.split(r\\'(?<=[.!?])\\\\s+\\', text)\\n    for sentence in sentences:\\n        sentence = sentence.strip()\\n        # Check for natural sentence structure\\n        if (len(sentence.split()) >= 7 and \\n            not sentence.startswith((\\'-\\', \\'—\\', \\'«\\')) and\\n            \\':\\' not in sentence and \\n            not any(word in sentence for word in [\\'аныктама\\', \\'дегенди билдирет\\', \\'мааниси\\'])):\\n            return sentence\\n    \\n    return text.strip()\\n\\ndef clean_sentence(sentence):\\n    \"\"\"Clean up the sentence to remove definition-like structures\"\"\"\\n    if not sentence:\\n        return \"\"\\n    \\n    # Remove definition markers and English terms\\n    sentence = re.sub(r\\'^[-—]\\\\s*\\', \\'\\', sentence)  # Remove starting hyphen/dash\\n    sentence = re.sub(r\\'[\"\\']\\', \\'\\', sentence)\\n    sentence = re.sub(r\\'\\\\s+\\', \\' \\', sentence).strip()\\n    \\n    # Remove any parenthetical English terms\\n    sentence = re.sub(r\\'\\\\([^)]*[a-zA-Z][^)]*\\\\)\\', \\'\\', sentence)\\n    \\n    # Remove common definition patterns\\n    sentence = re.sub(r\\'бул\\\\s+[^.]*\\\\.?\\\\s*\\', \\'\\', sentence)\\n    sentence = re.sub(r\\'деп\\\\s+аталат\\\\s*\\', \\'\\', sentence)\\n    sentence = re.sub(r\\'мааниси\\\\s*\\', \\'\\', sentence)\\n    \\n    # Ensure proper punctuation\\n    if sentence and not sentence.endswith((\\'.\\', \\'!\\', \\'?\\')):\\n        sentence += \\'.\\'\\n    \\n    # Capitalize first letter\\n    if sentence and sentence[0].islower():\\n        sentence = sentence[0].upper() + sentence[1:]\\n    \\n    return sentence\\n\\ndef is_valid_natural_sentence(sentence):\\n    \"\"\"Check if this is a valid natural Kyrgyz sentence about coding\"\"\"\\n    if not sentence or len(sentence) < 20:\\n        return False\\n    \\n    words = sentence.split()\\n    if len(words) < 7 or len(words) > 20:\\n        return False\\n    \\n    if not sentence[0].isupper() or not sentence.endswith((\\'.\\', \\'!\\', \\'?\\')):\\n        return False\\n    \\n    # Check for definition-like patterns to exclude\\n    definition_indicators = [\\n        \\'бул\\', \\'дегенди билдирет\\', \\'мааниси\\', \\'аныктама\\', \\'деп аталат\\',\\n        \\'-\\', \\'—\\', \\':\\', \\'(\\', \\')\\'\\n    ]\\n    \\n    if any(indicator in sentence.lower() for indicator in definition_indicators):\\n        return False\\n    \\n    # Check for English words\\n    if re.search(r\\'[a-zA-Z]\\', sentence):\\n        return False\\n    \\n    # Check for natural Kyrgyz sentence structure\\n    kyrgyz_indicators = [\\n        \\'менен\\', \\'үчүн\\', \\'болуп\\', \\'жана\\', \\'бирок\\', \\'андан\\', \\'кийин\\',\\n        \\'ошондо\\', \\'ошентсе\\', \\'аркылуу\\', \\'сайын\\', \\'бойдон\\'\\n    ]\\n    \\n    has_kyrgyz_structure = any(indicator in sentence.lower() for indicator in kyrgyz_indicators)\\n    \\n    return has_kyrgyz_structure\\n\\ndef save_progress(sentences, filename):\\n    \"\"\"Save progress to file\"\"\"\\n    with open(filename, \\'w\\', encoding=\\'utf-8\\') as f:\\n        for sentence in sentences:\\n            f.write(sentence + \\'\\n\\')\\n\\ndef test_ollama():\\n    \"\"\"Test if Ollama is working\"\"\"\\n    print(\"Testing Ollama connection...\")\\n    try:\\n        response = requests.get(\"http://localhost:11434/\", timeout=10)\\n        if response.status_code == 200:\\n            print(\"Ollama is running!\")\\n            \\n            # Test with natural topic\\n            test_result = generate_with_ollama(\"Python менен программа жазуунун жакшы тараптары\")\\n            if test_result:\\n                cleaned = clean_sentence(extract_sentence(test_result))\\n                print(f\"Model test successful: {cleaned}\")\\n                return True\\n            else:\\n                print(\"Model test failed\")\\n                return False\\n        else:\\n            print(f\"Ollama responded with: {response.status_code}\")\\n            return False\\n    except Exception as e:\\n        print(f\"Cannot connect to Ollama: {e}\")\\n        return False\\n\\ndef prepare_texts(num_sentences=9000):\\n    \"\"\"Main function to prepare natural coding texts\"\"\"\\n    if test_ollama():\\n        print(f\"\\nGenerating {num_sentences} natural coding sentences in Kyrgyz...\")\\n        print(\"This will take several hours...\")\\n        \\n        start_time = time.time()\\n        texts = generate_coding_sentences_ollama(num_sentences)\\n        end_time = time.time()\\n        \\n        duration = (end_time - start_time) / 3600\\n        print(f\"Successfully generated {len(texts)} natural sentences\")\\n        print(f\"Total time: {duration:.2f} hours\")\\n        \\n        return texts\\n    else:\\n        print(\"Ollama setup failed\")\\n        return []\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def generate_with_ollama(prompt, model=\"deepseek-coder-v2:latest\"):\n",
    "    \"\"\"Generate natural Kyrgyz sentences about coding topics\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\" #ollama hosted locally\n",
    "    \n",
    "    # More natural prompt without definition structure\n",
    "    enhanced_prompt = f\"\"\"\n",
    "Сиз программалоо жана технология темасында табигый кыргыз тилинде сүйлөмдөр жаратуучу AI болосуз.\n",
    "\n",
    "Тема: {prompt}\n",
    "\n",
    "Жарыялоо: Бул тема боюнча 7-15 сөздөн турган табигый, толук сүйлөм жаратыңыз.\n",
    "- Сүйлөм табигый кыргыз тилинде болсун\n",
    "- Англис сөздөрүн колдонбоңуз\n",
    "- Аныктама бербеңиз\n",
    "- Сүйлөм баш тамга менен башталып, чекит менен бүтсүн\n",
    "- Сүйлөм табигый жана коомдо колдонулган сыяктуу болсун\n",
    "\n",
    "Сүйлөм:\"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": enhanced_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.9,  # Increased for more creativity\n",
    "            \"num_predict\": 100,\n",
    "            \"top_p\": 0.95,\n",
    "            \"repeat_penalty\": 1.3\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result[\"response\"].strip()\n",
    "        else:\n",
    "            print(f\"API error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_coding_sentences_ollama(num_sentences=9000):\n",
    "    \"\"\"Generate natural coding/programming sentences in Kyrgyz\"\"\"\n",
    "    \n",
    "    # More conversational topics that encourage natural sentences\n",
    "    coding_topics = [\n",
    "        # Programming experiences\n",
    "        \"Python менен программа жазуунун жакшы тараптары\",\n",
    "        \"Java колдонуп жаңы проект түзүү\",\n",
    "        \"JavaScript жардамында динамикалык веб-беттер\",\n",
    "        \"C++ менен ыңгайлуу колдонмолор иштеп чыгуу\",\n",
    "        \"PHP аркылуу сервердик скриптер жазуу\",\n",
    "        \"Ruby программалоо тилин үйрөнүү тажрыйбасы\",\n",
    "        \n",
    "        # Daily programming activities\n",
    "        \"Код жазууда колдонулуучу негизги каражаттар\",\n",
    "        \"Программа иштебей калганда кылган аракеттер\",\n",
    "        \"Жаңы функция кошуудан мурун кандай даярдык кылуу\",\n",
    "        \"Башка программачылар менен бирге иштөө\",\n",
    "        \"Колдонмонун ырачатын жакшыртуу үчүн аракеттер\",\n",
    "        \"Кодду текшерүү жана оңдоо процесси\",\n",
    "        \n",
    "        # Learning and development\n",
    "        \"Программалоо тилин үйрөнүүдөгү кыйынчылыктар\",\n",
    "        \"Алгачкы программаңызды иштеткендеги сезимдер\",\n",
    "        \"Технологиялык жаңылыктарды күндөлүк көзөмөлдөө\",\n",
    "        \"Программалоо боюнча коомдук иш-чараларга катышуу\",\n",
    "        \"Жаңы технологияларды долбоордо колдонуу\",\n",
    "        \"Код жазуунун жакшы ыкмаларын үйрөнүү\",\n",
    "        \n",
    "        # Project scenarios\n",
    "        \"Ири проектти аяктоодон кийинки баалоо\",\n",
    "        \"Топ менен иштөөдө коммуникациянын маанилүүлүгү\",\n",
    "        \"Колдонмонун иштешине мониторинг жүргүзүү\",\n",
    "        \"Жаңы версия чыгарганда эске алынуучу жабдуулар\",\n",
    "        \"Колдонуучулардын пикири боюнча өзгөртүүлөр киргизүү\",\n",
    "        \"Программанын коопсуздугун камсыз кылуу чаралары\",\n",
    "        \n",
    "        # Problem solving\n",
    "        \"Программа иштебей калганда издөө ыкмалары\",\n",
    "        \"Кыйын маселе чечүү үчүн колдонулган стратегиялар\",\n",
    "        \"Кодду оңдоодо кезиккен кызыктуу учурлар\",\n",
    "        \"Башка адамдын кодун түшүнүүгө болгон машыгуу\",\n",
    "        \"Программанын ырачатын жогорулатуу жолдору\",\n",
    "        \"Техникалык көйгөй чечүүдөгү тажрыйбалар\"\n",
    "    ]\n",
    "    \n",
    "    sentences = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_sentences * 2\n",
    "    \n",
    "    print(f\"Starting generation of {num_sentences} natural coding sentences...\")\n",
    "    \n",
    "    while len(sentences) < num_sentences and attempts < max_attempts:\n",
    "        topic = random.choice(coding_topics)\n",
    "        \n",
    "        generated_text = generate_with_ollama(topic)\n",
    "        attempts += 1\n",
    "        \n",
    "        if generated_text:\n",
    "            # Extract just the sentence part\n",
    "            sentence = extract_sentence(generated_text)\n",
    "            sentence = clean_sentence(sentence)\n",
    "            \n",
    "            if is_valid_natural_sentence(sentence):\n",
    "                sentences.append(sentence)\n",
    "                print(f\"[{len(sentences)}/{num_sentences}] {sentence}\")\n",
    "                \n",
    "                # Save progress regularly\n",
    "                if len(sentences) % 100 == 0:\n",
    "                    save_progress(sentences, f\"progress_{len(sentences)}.txt\")\n",
    "                    print(f\"Progress saved: {len(sentences)} sentences\")\n",
    "            else:\n",
    "                if attempts % 10 == 0:\n",
    "                    print(f\"Attempt {attempts}: Retrying... Last output: {sentence[:60]}...\")\n",
    "        else:\n",
    "            print(f\"Generation failed on attempt {attempts}\")\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(1.5)  # Slightly longer delay for better quality\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def extract_sentence(text):\n",
    "    \"\"\"Extract the actual sentence from generated text\"\"\"\n",
    "    # Remove any prompt remnants\n",
    "    if \"Сүйлөм:\" in text:\n",
    "        text = text.split(\"Сүйлөм:\")[-1].strip()\n",
    "    \n",
    "    # Split into sentences and take the first complete one\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        # Check for natural sentence structure\n",
    "        if (len(sentence.split()) >= 7 and \n",
    "            not sentence.startswith(('-', '—', '«')) and\n",
    "            ':' not in sentence and \n",
    "            not any(word in sentence for word in ['аныктама', 'дегенди билдирет', 'мааниси'])):\n",
    "            return sentence\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    \"\"\"Clean up the sentence to remove definition-like structures\"\"\"\n",
    "    if not sentence:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove definition markers and English terms\n",
    "    sentence = re.sub(r'^[-—]\\s*', '', sentence)  # Remove starting hyphen/dash\n",
    "    sentence = re.sub(r'[\"\\']', '', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "    \n",
    "    # Remove any parenthetical English terms\n",
    "    sentence = re.sub(r'\\([^)]*[a-zA-Z][^)]*\\)', '', sentence)\n",
    "    \n",
    "    # Remove common definition patterns\n",
    "    sentence = re.sub(r'бул\\s+[^.]*\\.?\\s*', '', sentence)\n",
    "    sentence = re.sub(r'деп\\s+аталат\\s*', '', sentence)\n",
    "    sentence = re.sub(r'мааниси\\s*', '', sentence)\n",
    "    \n",
    "    # Ensure proper punctuation\n",
    "    if sentence and not sentence.endswith(('.', '!', '?')):\n",
    "        sentence += '.'\n",
    "    \n",
    "    # Capitalize first letter\n",
    "    if sentence and sentence[0].islower():\n",
    "        sentence = sentence[0].upper() + sentence[1:]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def is_valid_natural_sentence(sentence):\n",
    "    \"\"\"Check if this is a valid natural Kyrgyz sentence about coding\"\"\"\n",
    "    if not sentence or len(sentence) < 20:\n",
    "        return False\n",
    "    \n",
    "    words = sentence.split()\n",
    "    if len(words) < 7 or len(words) > 20:\n",
    "        return False\n",
    "    \n",
    "    if not sentence[0].isupper() or not sentence.endswith(('.', '!', '?')):\n",
    "        return False\n",
    "    \n",
    "    # Check for definition-like patterns to exclude\n",
    "    definition_indicators = [\n",
    "        'бул', 'дегенди билдирет', 'мааниси', 'аныктама', 'деп аталат',\n",
    "        '-', '—', ':', '(', ')'\n",
    "    ]\n",
    "    \n",
    "    if any(indicator in sentence.lower() for indicator in definition_indicators):\n",
    "        return False\n",
    "    \n",
    "    # Check for English words\n",
    "    if re.search(r'[a-zA-Z]', sentence):\n",
    "        return False\n",
    "    \n",
    "    # Check for natural Kyrgyz sentence structure\n",
    "    kyrgyz_indicators = [\n",
    "        'менен', 'үчүн', 'болуп', 'жана', 'бирок', 'андан', 'кийин',\n",
    "        'ошондо', 'ошентсе', 'аркылуу', 'сайын', 'бойдон'\n",
    "    ]\n",
    "    \n",
    "    has_kyrgyz_structure = any(indicator in sentence.lower() for indicator in kyrgyz_indicators)\n",
    "    \n",
    "    return has_kyrgyz_structure\n",
    "\n",
    "def save_progress(sentences, filename):\n",
    "    \"\"\"Save progress to file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for sentence in sentences:\n",
    "            f.write(sentence + '\\n')\n",
    "\n",
    "def test_ollama():\n",
    "    \"\"\"Test if Ollama is working\"\"\"\n",
    "    print(\"Testing Ollama connection...\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Ollama is running!\")\n",
    "            \n",
    "            # Test with natural topic\n",
    "            test_result = generate_with_ollama(\"Python менен программа жазуунун жакшы тараптары\")\n",
    "            if test_result:\n",
    "                cleaned = clean_sentence(extract_sentence(test_result))\n",
    "                print(f\"Model test successful: {cleaned}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Model test failed\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"Ollama responded with: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot connect to Ollama: {e}\")\n",
    "        return False\n",
    "\n",
    "def prepare_texts(num_sentences=9000):\n",
    "    \"\"\"Main function to prepare natural coding texts\"\"\"\n",
    "    if test_ollama():\n",
    "        print(f\"\\nGenerating {num_sentences} natural coding sentences in Kyrgyz...\")\n",
    "        print(\"This will take several hours...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        texts = generate_coding_sentences_ollama(num_sentences)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        duration = (end_time - start_time) / 3600\n",
    "        print(f\"Successfully generated {len(texts)} natural sentences\")\n",
    "        print(f\"Total time: {duration:.2f} hours\")\n",
    "        \n",
    "        return texts\n",
    "    else:\n",
    "        print(\"Ollama setup failed\")\n",
    "        return []\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts_from_file(filename=\"texts.txt\"):\n",
    "    \"\"\"Load texts from file for synthesis\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            texts = [line.strip() for line in f if line.strip()]\n",
    "        print(f\"Loaded {len(texts)} texts from {filename}\")\n",
    "        return texts\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653d3ca",
   "metadata": {},
   "source": [
    "#### Speech Synthesis with Matcha TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe59d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4602 texts from texts.txt\n",
      "Starting REAL Matcha TTS synthesis for 4602 texts from texts.txt...\n",
      "\n",
      "[1/4602] Processing: Дини Динден тышкары Аянты  Жалпы  Суу бетинин ....\n",
      "Created directory, looking for audio...\n",
      "Extracted audio: audio_files/1.wav\n",
      "Removed PNG file: utterance_001.png\n",
      "\n",
      "[2/4602] Processing: Түндүктө Казакстан, батышта жана түштүк-батышта Өз...\n",
      "Created directory, looking for audio...\n",
      "Extracted audio: audio_files/2.wav\n",
      "Removed PNG file: utterance_001.png\n",
      "\n",
      "[3/4602] Processing: Кыргызстан  басымдуу аймагы тоолуу аймактарды камт...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_220395/2211431478.py\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuccessful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0msuccessful\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynthesize_with_matcha_cli_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'texts.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_220395/2211431478.py\u001b[0m in \u001b[0;36msynthesize_with_matcha_cli_from_file\u001b[0;34m(text_file, output_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m             ]\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Check what was created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def synthesize_with_matcha_cli_from_file(text_file=\"texts.txt\", output_dir=\"audio_files\"):\n",
    "    \"\"\"Synthesize speech using texts from file\"\"\"\n",
    "    # Load texts from file\n",
    "    texts = load_texts_from_file(text_file)\n",
    "    if not texts:\n",
    "        print(\"No texts found to synthesize!\")\n",
    "        return 0\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Starting REAL Matcha TTS synthesis for {len(texts)} texts from {text_file}...\")\n",
    "    \n",
    "    successful = 0\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        try:\n",
    "            print(f\"\\n[{i}/{len(texts)}] Processing: {text[:50]}...\")\n",
    "            \n",
    "            # Use a temporary output name that's definitely a file\n",
    "            temp_output = f\"temp_audio_{i}.wav\"\n",
    "            final_output = f\"{output_dir}/{i}.wav\"\n",
    "            \n",
    "            # Clean up any existing temp files\n",
    "            if os.path.exists(temp_output):\n",
    "                if os.path.isfile(temp_output):\n",
    "                    os.remove(temp_output)\n",
    "                else:\n",
    "                    shutil.rmtree(temp_output)\n",
    "            \n",
    "            # Run Matcha TTS with output parameter\n",
    "            cmd = [\n",
    "                'matcha-tts',\n",
    "                '--text', text,\n",
    "                '--output', temp_output\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n",
    "            \n",
    "            # Check what was created\n",
    "            if os.path.exists(temp_output):\n",
    "                if os.path.isfile(temp_output):\n",
    "                    # It's a proper file, move to final location\n",
    "                    shutil.move(temp_output, final_output)\n",
    "                    print(f\"Created: {final_output}\")\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    # It's a directory, look for WAV files inside\n",
    "                    print(f\"Created directory, looking for audio...\")\n",
    "                    wav_files = list(Path(temp_output).glob(\"*.wav\"))\n",
    "                    if wav_files:\n",
    "                        # Move the first WAV file to final location\n",
    "                        first_audio = wav_files[0]\n",
    "                        shutil.move(str(first_audio), final_output)\n",
    "                        shutil.rmtree(temp_output)\n",
    "                        print(f\"Extracted audio: {final_output}\")\n",
    "                        successful += 1\n",
    "                    else:\n",
    "                        print(f\"No audio files in directory\")\n",
    "                        shutil.rmtree(temp_output)\n",
    "            else:\n",
    "                print(f\"No output created\")\n",
    "            \n",
    "            # CLEAN UP: Remove any PNG files created by Matcha TTS\n",
    "            png_files = list(Path(\".\").glob(\"*.png\"))\n",
    "            for png_file in png_files:\n",
    "                try:\n",
    "                    png_file.unlink()\n",
    "                    print(f\"Removed PNG file: {png_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not remove {png_file}: {e}\")\n",
    "                \n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"Timeout\")\n",
    "            # Clean up temp files AND any PNG files\n",
    "            if os.path.exists(f\"temp_audio_{i}.wav\"):\n",
    "                if os.path.isfile(f\"temp_audio_{i}.wav\"):\n",
    "                    os.remove(f\"temp_audio_{i}.wav\")\n",
    "                else:\n",
    "                    shutil.rmtree(f\"temp_audio_{i}.wav\")\n",
    "            # Clean up PNG files on timeout too\n",
    "            png_files = list(Path(\".\").glob(\"*.png\"))\n",
    "            for png_file in png_files:\n",
    "                try:\n",
    "                    png_file.unlink()\n",
    "                except:\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            # Clean up temp files AND any PNG files\n",
    "            if os.path.exists(f\"temp_audio_{i}.wav\"):\n",
    "                if os.path.isfile(f\"temp_audio_{i}.wav\"):\n",
    "                    os.remove(f\"temp_audio_{i}.wav\")\n",
    "                else:\n",
    "                    shutil.rmtree(f\"temp_audio_{i}.wav\")\n",
    "            # Clean up PNG files on error too\n",
    "            png_files = list(Path(\".\").glob(\"*.png\"))\n",
    "            for png_file in png_files:\n",
    "                try:\n",
    "                    png_file.unlink()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(f\"\\n Synthesis completed: {successful}/{len(texts)} successful\")\n",
    "    return successful\n",
    "\n",
    "successful = synthesize_with_matcha_cli_from_file('texts.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7c389",
   "metadata": {},
   "source": [
    "#### Demonstrate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ab3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting audio demonstration...\n",
      "\n",
      "============================================================\n",
      "AUDIO FILES DEMONSTRATION\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147119/2622993592.py\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting audio demonstration...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mdemonstrate_audio_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_to_show\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0manalyze_audio_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_147119/2622993592.py\u001b[0m in \u001b[0;36mdemonstrate_audio_files\u001b[0;34m(audio_dir, num_to_show)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get list of audio files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maudio_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0maudio_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Audio Demonstration Section\n",
    "def demonstrate_audio_files(audio_dir=\"audio_files\", num_to_show=5):\n",
    "    \"\"\"Display and play sample audio files with analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AUDIO FILES DEMONSTRATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get list of audio files\n",
    "    audio_files = list(Path(audio_dir).glob(\"*.wav\"))\n",
    "    audio_files.sort(key=lambda x: int(x.stem))\n",
    "    \n",
    "    # Read the text file to show corresponding texts\n",
    "    with open(\"texts.txt\", 'r', encoding='utf-8') as f:\n",
    "        text_lines = f.readlines()\n",
    "    \n",
    "    print(f\"Found {len(audio_files)} audio files\")\n",
    "    print(f\"Showing first {min(num_to_show, len(audio_files))} files for demonstration\\n\")\n",
    "    \n",
    "    for i, audio_file in enumerate(audio_files[:num_to_show]):\n",
    "        print(f\"\\n{'─'*50}\")\n",
    "        print(f\"🎵 AUDIO FILE {i+1}: {audio_file.name}\")\n",
    "        print(f\"{'─'*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Load audio data\n",
    "            audio_data, sample_rate = sf.read(str(audio_file))\n",
    "            duration = len(audio_data) / sample_rate\n",
    "            \n",
    "            # Display file information\n",
    "            print(f\"File Info:\")\n",
    "            print(f\"   • Duration: {duration:.2f} seconds\")\n",
    "            print(f\"   • Sample rate: {sample_rate} Hz\")\n",
    "            print(f\"   • Channels: {audio_data.shape[1] if len(audio_data.shape) > 1 else 1}\")\n",
    "            print(f\"   • File size: {os.path.getsize(audio_file) / 1024:.1f} KB\")\n",
    "            \n",
    "            # Display corresponding text\n",
    "            if i < len(text_lines):\n",
    "                text_preview = text_lines[i].strip()\n",
    "                # Truncate long texts for display\n",
    "                if len(text_preview) > 100:\n",
    "                    text_preview = text_preview[:100] + \"...\"\n",
    "                print(f\"Text: {text_preview}\")\n",
    "            \n",
    "            # Create a simple waveform visualization\n",
    "            plt.figure(figsize=(10, 3))\n",
    "            \n",
    "            # Handle both mono and stereo audio\n",
    "            if len(audio_data.shape) > 1:\n",
    "                audio_mono = audio_data.mean(axis=1)\n",
    "            else:\n",
    "                audio_mono = audio_data\n",
    "            \n",
    "            # Plot first 2 seconds or entire audio if shorter\n",
    "            samples_to_plot = min(len(audio_mono), int(2 * sample_rate))\n",
    "            time_axis = np.linspace(0, samples_to_plot/sample_rate, samples_to_plot)\n",
    "            \n",
    "            plt.plot(time_axis, audio_mono[:samples_to_plot], color='blue', alpha=0.7)\n",
    "            plt.title(f'Audio Waveform: {audio_file.name}')\n",
    "            plt.xlabel('Time (seconds)')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display audio player\n",
    "            print(\"Audio Player:\")\n",
    "            display(Audio(str(audio_file)))\n",
    "            \n",
    "            # Add small delay between files for better presentation\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying {audio_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Audio demonstration completed!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "def analyze_audio_quality(audio_dir=\"audio_files\"):\n",
    "    \"\"\"Analyze the quality and characteristics of generated audio files\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AUDIO QUALITY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    audio_files = list(Path(audio_dir).glob(\"*.wav\"))\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"No audio files found for analysis\")\n",
    "        return\n",
    "    \n",
    "    durations = []\n",
    "    file_sizes = []\n",
    "    \n",
    "    for audio_file in audio_files:\n",
    "        try:\n",
    "            audio_data, sample_rate = sf.read(str(audio_file))\n",
    "            duration = len(audio_data) / sample_rate\n",
    "            file_size = os.path.getsize(audio_file) / 1024  # KB\n",
    "            \n",
    "            durations.append(duration)\n",
    "            file_sizes.append(file_size)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {audio_file.name}: {e}\")\n",
    "    \n",
    "    if durations:\n",
    "        print(f\"Statistics for {len(durations)} audio files:\")\n",
    "        print(f\"   Average duration: {np.mean(durations):.2f} seconds\")\n",
    "        print(f\"   Duration range: {min(durations):.2f}s - {max(durations):.2f}s\")\n",
    "        print(f\"   Total audio duration: {sum(durations)/60:.2f} minutes\")\n",
    "        print(f\"   Average file size: {np.mean(file_sizes):.1f} KB\")\n",
    "        print(f\"   Total storage used: {sum(file_sizes)/1024:.2f} MB\")\n",
    "        \n",
    "        # Create summary plot\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(durations, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.xlabel('Duration (seconds)')\n",
    "        plt.ylabel('Number of Files')\n",
    "        plt.title('Audio Duration Distribution')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(file_sizes, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        plt.xlabel('File Size (KB)')\n",
    "        plt.ylabel('Number of Files')\n",
    "        plt.title('File Size Distribution')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Run the demonstration\n",
    "print(\"Starting audio demonstration...\")\n",
    "\n",
    "demonstrate_audio_files(num_to_show=5) \n",
    "\n",
    "analyze_audio_quality()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac91605",
   "metadata": {},
   "source": [
    "#### Create archive file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING FINAL ARCHIVE\n",
      "============================================================\n",
      "Added texts.txt\n",
      "Added 3 audio files\n",
      "\n",
      " Archive created successfully!\n",
      "   Archive name: bvt2201_nyathi_17_matcha_kyrgyz.tar.gz\n",
      "   Archive size: 3784.54 KB\n",
      "   Text files: 1\n",
      "   Audio files: 3\n",
      "   First 5 files: ['texts.txt', 'audio_files/1.wav', 'audio_files/2.wav', 'audio_files/3.wav']\n",
      "Archive file: bvt2201_nyathi_17_matcha_kyrgyz.tar.gz\n"
     ]
    }
   ],
   "source": [
    "def create_archive():\n",
    "    archive_name = \"bvt2201_nyathi_17_matcha_kyrgyz.tar.gz\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING FINAL ARCHIVE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with tarfile.open(archive_name, \"w:gz\") as tar:\n",
    "        # Add text file\n",
    "        if os.path.exists(\"texts.txt\"):\n",
    "            tar.add(\"texts.txt\")\n",
    "            print(\"Added texts.txt\")\n",
    "        \n",
    "        # Add audio files\n",
    "        audio_dir = \"audio_files\"\n",
    "        if os.path.exists(audio_dir):\n",
    "            audio_files = list(Path(audio_dir).glob(\"*.wav\"))\n",
    "            for audio_file in audio_files:\n",
    "                tar.add(audio_file)\n",
    "            print(f\"Added {len(audio_files)} audio files\")\n",
    "    \n",
    "    # Check archive size and contents\n",
    "    archive_size = os.path.getsize(archive_name) / 1024  # Size in KB\n",
    "    print(f\"\\n Archive created successfully!\")\n",
    "    print(f\"   Archive name: {archive_name}\")\n",
    "    print(f\"   Archive size: {archive_size:.2f} KB\")\n",
    "    \n",
    "    # Show archive contents\n",
    "    with tarfile.open(archive_name, \"r:gz\") as tar:\n",
    "        members = tar.getnames()\n",
    "        text_files = [f for f in members if f.endswith('.txt')]\n",
    "        audio_files = [f for f in members if f.endswith('.wav')]\n",
    "        \n",
    "        print(f\"   Text files: {len(text_files)}\")\n",
    "        print(f\"   Audio files: {len(audio_files)}\")\n",
    "        print(f\"   First 5 files: {members[:5]}\")\n",
    "    \n",
    "    return archive_name\n",
    "\n",
    "# Create the archive\n",
    "archive_path = create_archive()\n",
    "\n",
    "print(f\"Archive file: {archive_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
