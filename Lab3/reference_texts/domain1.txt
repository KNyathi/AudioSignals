Трансформерные архитектуры, основанные на механизмах внимания, кардинально изменили подходы к обработке естественного языка, демонстрируя state-of-the-art результаты в задачах машинного перевода и генерации текста.